---
title: "Specifying enrollment, failure and dropout rates with implications"
author: "Keaven M. Anderson"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: gsDesign.bib
vignette: >
  %\VignetteIndexEntry{Time-to-event endpoint design with a cure model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

options( width = 58 )

```

# Introduction

Most often timing for analyses for studies with time-to-event endpoints is planned based on event counts. Enrollment rates and failure rates over time have a substantial impact on the rate of accumulation of endpoints, and thus on the calendar timing of analyses. 
There is also the option of doing analyses based on calendar timing, but then the event counts at analyses can be substantially impacted by enrollment and failure rates.
Thus, it is worth thinking carefully at the time of study design about expected failure rates over time for both control and experimental treatment groups as well as expected enrollment rates.
The **gsDesign** package has tools for computing sample size and expected accumulation of events for a piecewise exponential model that can be used to approximate any set of enrollment rates and failure rates. 
For sample size calculations, there is a current limitation to proportional hazards model for treatment effect.
However, expect event accumulation can be computed under arbitrary treatment effects.

In this document, we consider a single example for enrollment rates and consider various models for failure rate distributions to demonstrate

- the impact of different assumptions on event rate accumulation, and
- how to implement different assumptions on enrollment, failure and dropout rates in the **gsDesign** package.



At time of study design for a time-to-event study it is worth considering the shape of the distribution for the control group based on historical data. 
The default distribution for `gsSurv()` and `nSurv()` is an exponential distribution which could be inadequate for cases where, say, there is a high failure rate period followed by a lower failure rate period. 
The study designer may wish approximate such a situation by using a piecewise exponential failure rate assumption with 2 or more pieces.
This can be extended in the extreme to frequent changes in the hazard rate to approximate a continuously changing hazard rate such as that in a cure model. 
We demonstrate both of these extremes here and see the impact on study planning.
In all cases, we assume a proportional hazards model.
This is an extension of the vignette on basic time-to-event endpoint design with the assumption of exponential failure times and still applies the @LachinFoulkes sample size method.

# Common assumptions

For the piecewise exponential distribution, there may be an arbitrary number of points with decreasing survival in $(0,1)$ as time $>0$ increases.
For other models below, we will consider the first 2 values specified here.


```{r}
times <- c(6,12,18)
survAtTimes <- c(.7,.61,.55)
```

The cumulative hazard at each time point will be useful for calculations in some cases.

```{r}
HazardAtTimes <- -log(survAtTimes)
HazardAtTimes
```

We will also assume piecewise constant enrollment rates and a constant exponential dropout rate; this could just as easily be specified as piecewise exponential using the same interval durations at the piecewise exponential failure rates.

```{r}
dropoutRates <- .001
enrollRates <- c(5,10,20,30)
enrollRateDurations <- c(2,2,2,10)
# Specify trial duration if enrollment rates to be changed
# or leave NULL if enrollment rates fixed and duration set to achieve power
T <-NULL
# Specify the number of time points from 0 to T for model approximations
npts <- 50
# max range for approximations to survival curves
maxT <- 60
# minimum follow-up for last patient enrolled
minfup <- 18
```

The following requires no modification, but will be used below for cure models below where we will approximate continuously changing hazard rates with a step function.

```{r}
# used for models continuously changing hazard rates 
tx <- seq(maxT/npts,maxT,maxT/npts)
```

For group sequential designs below, we will use many defaults which the user can change as noted in the vignette on basic design time-to-event endpoints.
This allows the reader to focus on survival distribution assumptions in this vignette.
We will make explicit the assumed hazard ratio for experimental vs. control therapy since that does drive the experimental group failure distribution.

```{r}
hr <- .7 # Alternate hypothesis hazard ratio
```


# Piecewise exponential distribution

We consider first a piecewise exponential distribution with
constant hazard rates are between points specifed in `times`.
The rates yielding survival `survAtTimes` at times specified in `times` are computed as:

```{r}
k <- length(HazardAtTimes)-1
failRateDurationsPWE <- times-c(0,times[1:k])
failRatesPWE <- (HazardAtTimes-c(0,HazardAtTimes[1:k]))/failRateDurationsPWE
failRatesPWE
```

## Group sequential design

```{r,message=FALSE}
library(gsDesign)
designPWE <- gsSurv(hr = hr,
                    # failure rates
                    lambdaC = failRatesPWE,
                    # failure rate durations; exclude last
                    S = failRateDurationsPWE[1:k],
                    # dropout rates
                    eta = dropoutRates,
                    # enrollment rates
                    gamma = enrollRates,
                    # enrollment rate durations
                    R = enrollRateDurations,
                    # Trial duration
                    T = T,
                    # minimum follow-up
                    minfup = minfup
                   )
```

Now we summarize the design. We have placed analyses at equally spaced event counts.
Note that the calendar timing is not equally spaced.

```{r}
library(gt)
gsBoundSummary(designPWE) %>% 
  gt() %>% 
  tab_header(title="Group sequential design with piecewise exponential failure",
             subtitle="Analyses at equally spaced by event counts")
```

## Design duration and enrollment rates

If you left `T=NULL`, then the following enrollment rates should match the input you specified.

```{r}
designPWE$gamma %>%
  gt(rownames_to_stub=TRUE) %>%
  tab_header(title="Design enrollment rates",
             subtitle=" with periods of enrollment")
```

Adding minimum follow-up to total duration of enrollment gives estimated trial duration to achieve targeted enrollment and event counts at each analysis:

```{r}
# total enrollment duration + minimum follow-up
sum(designPWE$R) + designPWE$minfup
# timing of interim and final analyses
designPWE$T
```

## Computing expected enrollment and event accumulation over time

Now we can compute expected enrollment as a function of time.
Note that at this point we 

```{r}
library(purrr)
mx <- max(designPWE$T)
timesPWE <- c(1:floor(mx),mx)
qplot(x=c(0,timesPWE),y=c(0,map_dbl(timesPWE,nEventsIA,x=designPWE)),geom="line")+
  labs(x="Trial month",y="Expected events")
```




## Exponential with cure model

The exponential with cure model is a mixture of a proportion of patients $c$ that will never experience an event (cured) and the other proportion $1-c$ who have events according to an exponential distribution with failure rate $\lambda$.
The survival and cumulative hazard functions for this are:

$$S_{C}(t)=c+(1-c)\exp(-\lambda t),$$

We solve for $c$ and $\lambda$ based on an pair of known results for $i=1,2$:

$$s_i= c+(1-c)\exp(-\lambda t_i)$$

where $t_i$ and $s_i$ represent the times and milestone survival above.
A solution is generally easy to find through fixed point iteration. 
For this, we note that

$$\lambda = -\ln\left.\left(\frac {s_i-c}{1-c}\right)\right/t_i$$
and

$$c=\frac{s_i-\exp(-\lambda t_i)}{1-\exp(-\lambda t_i)}.$$

A small number of iterations of the following generally will produce a satisfactory solution fitting the first 2 points on the survival curve above.
This is a fixed point iteration algorithm solving for $\lambda$ in the first line and for $c$ in the second. While the algorithm is not guaranteed to converge, it is often the quickest way to solve a set of non-linear equations with a small number of unknown parameters.

```{r}
cureRate <- survAtTimes[2]/2
for(i in 1:15){
  lambdaEWC <- -log((survAtTimes[1]-cureRate)/(1-cureRate))/times[1]
  cureRate <- (survAtTimes[2]-exp(-lambdaEWC*times[2]))/(1-exp(-lambdaEWC*times[2]))
}
# compute survival and subtract target to see if difference is 0
cureRate+(1-cureRate)*exp(-lambdaEWC*times[1:2])-survAtTimes[1:2]
```

The resulting cure and exponential failure rates are `r round(cureRate,4)` and `r round(lambdaEWC,6)`, respectively. 
Note that a proportional hazards model means a failure distribution for the experimental group that is not in the exponential with cure model family.

## Poisson mixture model

The Poisson mixture model is another cure model that works nicely in that a proportional hazards assumption for the experimental group versus control produces another Poisson mixture model. We consider the simplest version of this:

$$S(t)=\exp[-\theta(1-\exp(-\lambda t))].$$
The cumulative hazard function is, thus, given by:

$$H(t)=-\ln(S(t))= \theta(1-\exp(-\lambda t)).$$
We can again take a fixed point iteration approach to solving this pair of unknowns using only the first 2 points in the survival curve specified:

```{r}
lambdaPM <- HazardAtTimes[1]/times[1]
for(i in 1:20){
  theta <- HazardAtTimes[2]/(1-exp(-lambdaPM*times[2]))
  lambdaPM <- -log(1-HazardAtTimes[1]/theta)/times[1]
#  print(c(theta,lambdaPM,exp(-theta*(1-exp(-lambdaPM*times)))))
}
# check that difference between rates and targets is 0
survAtTimes[1:2] - exp(-theta*(1-exp(-lambdaPM*times[1:2])))
```
 
With this, we have $\theta=$`r round(theta,4)` and $\lambda=$`r round(lambdaPM,6)`.


# Approximating a model with piecewise exponential survival

## Milestone survival rates

We can derive a piecewise exponential failure distribution approximating an arbitrary cumulative hazard function $H(t)$ by choosing a series of points $t_i$ starting with $t_0=0$ and approximating for $i>0$ with hazard rates $\lambda_i$ in $(t_{i-1},t_i]$ with:

$$\lambda_i=\frac{H(t_i)-H(t_{i-1})}{t_i-t_{i-1}}.$$

While a fairly small set of times $t_i$ may be perfectly adequate, computations for the functions `nSurv()` and `gsSurv()` used for sample size computation can accomodate a large number of points easily.

For our first example, we consider the simple piecewise exponential model where we specified survival rates at a fixed set of points. 
We set up piecewise exponential failure rates to match the survival at these times by using constant failure rates between sequential points specified.

```{r}
lambdaPWE <- (HazardAtTimes-c(0,HazardAtTimes[1:k]))/(times-c(0,times[1:k]))
lambdaPWE
```




# References